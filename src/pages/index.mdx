---
layout: ../layouts/Layout.astro
title: 'SCUBA: Salesforce Computer Use Benchmark'
description: Simple project page template for your research paper, built with Astro and Tailwind CSS
favicon: crmbench.png
thumbnail: screenshot-light.png
---

import Header from "../components/Header.astro";
import Video from "../components/Video.astro";
import HighlightedSection from "../components/HighlightedSection.astro";
import SmallCaps from "../components/SmallCaps.astro";
import Figure from "../components/Figure.astro";
import Image from "../components/Image.astro";
import TwoColumns from "../components/TwoColumns.astro";
import YouTubeVideo from "../components/YouTubeVideo.astro";
import LaTeX from "../components/LaTeX.astro";
import QA from "../components/QA.astro";

import { ImageComparison } from "../components/ImageComparison.tsx";
import PerformanceTable from "../components/PerformanceTable.tsx";

import demo from "../assets/demo.mp4";
import transformer from "../assets/transformer.webp";
import Splat from "../components/Splat.tsx"
import task_distribution from "../assets/task_distribution.png"
import task_difficulty from "../assets/task_difficulty.png"
import pareto_front_costs_success_rate from "../assets/pareto_front_costs_success_rate.png"
import pareto_front_time_success_rate from "../assets/pareto_front_time_success_rate.png"
import apply_for_a_org from "../assets/apply_for_a_org.png"


import CodeBlock from "../components/CodeBlock.astro";
import Table from "../components/Table.astro";
export const components = {pre: CodeBlock, table: Table}

<Header
  title={frontmatter.title}
  authors={[
    {
      name: "Yutong Dai",
      url: "https://roth.rbind.io",
      // institution: "Independent",
     // notes: ["*", "‚Ä†"],
    },
    {
      name: "Krithika Ramakrishnan",
      url: "https://www.linkedin.com/in/krithika-ramakrishnan-1a34b3109/",
    },
    {
      name: "Jing Gu",
      url: "https://g-jing.github.io/",
    },
    {
      name: "Matthew Fernandez",
      url: "https://www.linkedin.com/in/matthew-fernandez-32b19814b/"
    },
    {
      name: "Yanqi Luo",
      url: "https://www.linkedin.com/in/yanqi-luo/"
    },
    {
      name: "Viraj Prabhu",
      url: "https://virajprabhu.github.io/"
    },
    {
      name: "Zhenyu Hu",  
      url: "https://www.linkedin.com/in/eric-hu-92136a20/"
    },
    {
      name: "Silvio Savarese",
      url: "https://www.linkedin.com/in/silvio-savarese-97b76114/"
    },
    {
      name: "Caiming Xiong",
      url: "http://cmxiong.com/"
    },
    {
      name: "Zeyuan Chen",
      url: "https://www.linkedin.com/in/zeyuan-chen-0253b6141/"

    },
    {
      name: "Ran Xu",
      url: "https://www.linkedin.com/in/ran-xu-a2765924/"
    }
  ]}
  conference="Salesforce AI Research"
  notes={[
  //  {
  //    symbol: "*",
  //    text: "author note one",
  //  },
  //  {
  //    symbol: "‚Ä†",
  //    text: "author note two",
  //  },
  ]}
  links={[
    //{
    //  name: "Paper",
    //  url: "",
    //  icon: "ri:file-pdf-2-line",
    //},
    // search icon here: https://remixicon.com/icon/cloud-line
    {
      name: "arXiv",
      url: "https://arxiv.org/pdf/2509.26506",
      icon: "academicons:arxiv",
    },
    {
      name: "Code (coming soon)",
      url: "https://github.com/SalesforceAIResearch/SCUBA",
      icon: "ri:github-line",
    },
    {
      name: "Environment",
      url: "#create_org",
      icon: "ri:cloud-line",
    },
    {
      name: "Leaderboard",
      url: "#leaderboard",
      icon: "ri:bar-chart-2-line",
    }
  ]}
  />

<Video source={demo} />

<HighlightedSection>
## üì¢ Updates

[2025-09-30] SCUBA paper is now available on arXiv!


</HighlightedSection>

## Abstract

We introduce SCUBA, a benchmark designed to evaluate computer-use agents on customer relationship management (CRM) workflows within the Salesforce platform. SCUBA contains 300 task instances derived from real user interviews, spanning three primary personas‚Äîplatform administrators, sales representatives, and service agents. The tasks test a range of enterprise-critical abilities, including Enterprise Software UI navigation, data manipulation, workflow automation, information retrieval, and troubleshooting. To ensure realism, SCUBA operates in Salesforce sandbox environments with support for parallel execution and fine-grained evaluation metrics to capture milestone progress. We benchmark a diverse set of agents under both zero-shot and demonstration-augmented settings. We observed huge performance gaps in different agent design paradigms and gaps between the open-source model and the closed-source model. In the zero-shot setting, open-source model powered computer-use agents that have strong performance on related benchmarks like OSWorld only have less than 5\% success rate on SCUBA, while methods built on closed-source models can still have up to 39\% task success rate. In the demonstration-augmented settings, task success rates can be improved to 50\% while simultaneously reducing time and costs by 13\% and 16\%, respectively. These findings highlight both the challenges of enterprise tasks automation and the promise of agentic solutions. By offering a realistic benchmark with interpretable evaluation, SCUBA aims to accelerate progress in building reliable computer-use agents for complex business software ecosystems.


{/* ## Figures

Use the figure component to display images, videos, equations, or any other element, with an optional caption.

<Figure>
  <Image slot="figure" source={transformer} altText="Diagram of the transformer deep learning architecture." />
  <span slot="caption">Diagram of the transformer deep learning architecture.</span>
</Figure> */}

## Benchmark Statistics

SCUBA contains 300 task instances, instantiated from 60 task templates, covering three primary personas‚Äîplatform administrators, sales representatives, and service agents. Each split has 3 levels of difficulty. Each instance has a evaulator and assigns 2 to 5 milestone scores, serving as the process reward.

<TwoColumns>
  <Figure slot="left">
    <Image slot="figure" source={task_distribution} altText="." />
  <span slot="caption">Tasks distribution in different domains.</span>
  </Figure>
  <Figure slot="right">
    <Image slot="figure" source={task_difficulty} altText="." />
  <span slot="caption">Difficulty distribution by splits.</span>
  </Figure>
</TwoColumns> 

#### Sample Tasks

* [Admin/dashboard] I want to create a report using the Accounts type and name it MyAccountsRPT. If no data shows up in the preview, click All Time so it includes results from all time. Then add filters so it only shows records where Industry is Technology and Annual Revenue is greater than 1,000,000. If you don‚Äôt see the Industry or Annual Revenue fields in the table, add them first.
* [Sales/opportunity] Quick follow-up from my chat with Sarah Kim (Director of Operations) at Next Horizon Technologies. Definite potential here. Please: - Create an account for Next Horizon Technologies - Set Jordan Lee as the point of contact - Mobile: 777-444-1111.
* [Service/case] Please set up a case assignment rule called Billing Cases Assignment Rule. Route any case to the billing support queue if the description mentions ‚Äúbilling‚Äù or if the case number begins with 5. Give the description condition higher precedence, so it‚Äôs evaluated first.


{/* ## LaTeX */}

{/* You can also add LaTeX formulas, rendered during the build process using [KaTeX](https://katex.org/) so they're quick to load for visitors of your project page. You can write them inline, like this: <LaTeX inline formula="a^2 + b^2 = c^2" />. Or, you can write them as a block:

<LaTeX formula="\int_a^b f(x) dx" /> */}



## Leaderboard

<div id="leaderboard"></div>

<PerformanceTable client:load />



{/* You can add simple tables using [GitHub Flavored Markdown syntax](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/organizing-information-with-tables):

| Model | Accuracy | F1 score | Training time (hours) |
| :--- | :---: | :---: | :---: |
| BERT-base | 0.89 | 0.87 | 4.5 |
| RoBERTa-large | 0.92 | 0.91 | 7.2 |
| DistilBERT | 0.86 | 0.84 | 2.1 |
| XLNet | 0.90 | 0.89 | 6.8 | */}

## Task Success, Efficiency, and Cost Trade-off

For enterprise use cases, while having high success rates is crucial, costs and latency are also important factors. We visualize the agents‚Äô performance metrics in the following two figures. Orange squares and blue circles represent the browser-use agents and computer-use agents‚Äô performance metrics under zero-shot setting. The
arrow points the performance metrics under the demonstration-augmented setting. The arrow that points to
top-left are desired, since it means improvements. Green zone means low costs/latency and high success rates
zone; vice versa for the red zone.

<Figure>
  <Image slot="figure" source={pareto_front_costs_success_rate} altText="Costs v.s. Success Rate." />
  <span slot="caption">Costs v.s. Success Rate.</span>
</Figure>

<Figure>
  <Image slot="figure" source={pareto_front_time_success_rate} altText="Time v.s. Success Rate." />
  <span slot="caption">Time v.s. Success Rate.</span>
</Figure>





<HighlightedSection>
## FAQs

<div id="create_org"></div>

<QA>
  <div slot="question">How apply for a Salesforce developer sandbox org?</div>
  <div slot="answer">
    To apply for a developer org, please visit <code>https://www.salesforce.com/form/developer-signup/?d=pb</code>.
    You need to fill the required information and submit the form. Make sure the `Work Email` is your real email that can receive the verification code. Other fields can be filled with any information. Once the org is created, you can follow the instructions you received by email to access the org. For more details, please refer to the tutorial on our github repo [readme](https://github.com/SalesforceAIResearch/SCUBA?tab=readme-ov-file#setup-your-salesforce-developer-org).
    {/* <Image slot="figure" source={apply_for_a_org} altText="Apply for a Salesforce developer sandbox org." /> */}
  </div>
</QA>

</HighlightedSection>

## BibTeX citation

```bibtex
@misc{dai2025scubasalesforcecomputeruse,
      title={SCUBA: Salesforce Computer Use Benchmark}, 
      author={Yutong Dai and Krithika Ramakrishnan and Jing Gu and Matthew Fernandez and Yanqi Luo and Viraj Prabhu and Zhenyu Hu and Silvio Savarese and Caiming Xiong and Zeyuan Chen and Ran Xu},
      year={2025},
      eprint={2509.26506},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2509.26506}, 
}
```